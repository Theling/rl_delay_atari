program: run_experiment_rl_delay.py
method: grid
metric:
  goal: maximize
  name: episodic_reward
parameters:
  env_name:
    values: ['MsPacman-v0']
  augment_state:
    values: [False]
  delay_value:
    values: [0, 5, 10, 15, 30, 50]
  train_freq:
    values: [4]
  exploration_initial_eps:
    values: [1.0]
  learning_rate:
    values: [0.0001]
  target_network_update_freq:
    values: [1000]
  exploration_final_eps:
    values: [0.001]
  buffer_size:
    values: [5000, 10000, 50000, 100000]
  seed:
    values: [1]

program: run_experiment_rl_delay.py
method: grid
metric:
  goal: maximize
  name: episodic_reward
parameters:
  env_name:
    values: ['AssaultNoFrameskip-v4', 'BreakoutNoFrameskip-v4', 'AtlantisNoFrameskip-v4'] #['MsPacmanNoFrameskip-v4']
  agent_type:
    values: ['delayed', 'augmented', 'oblivious']
  delay_value:
    values: [0, 5, 15, 25]
  train_freq:
    values: [4]
  exploration_initial_eps:
    values: [1.0]
  learning_rate:
    values: [0.0001]
  target_network_update_freq:
    values: [1000]
  exploration_final_eps:
    values: [0.001]
  buffer_size:
    values: [25000]
  seed:
    values: [1, 2, 3]
  prioritized_replay:
    values: [True]
  fixed_frame_skip:
    values: [True]
  clone_full_state:
    values: [False]
  load_pretrained_agent:
    values: [False]

